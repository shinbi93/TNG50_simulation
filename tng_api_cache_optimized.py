"""
TNG API ë¶„ì„ - ìºì‹œ ìš°ì„  ë²„ì „

ìºì‹œ ì‹œìŠ¤í…œ:
- í•œ ë²ˆ ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ëŠ” ìë™ ì €ì¥
- ì¬ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ ì—†ì´ ì¦‰ì‹œ ë¡œë“œ
- í•„ìš”ì‹œ ìºì‹œ ì‚­ì œë¡œ ì¬ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥

ì‚¬ìš©ë²•:
1. ì²˜ìŒ ì‹¤í–‰: ë°ì´í„° ë‹¤ìš´ë¡œë“œ + ìºì‹œ ì €ì¥
2. ë‹¤ì‹œ ì‹¤í–‰: ìºì‹œì—ì„œ ì¦‰ì‹œ ë¡œë“œ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)
3. ìºì‹œ ì‚­ì œ: rm -rf tng_api_cache/
"""

import requests
import numpy as np
import h5py
import json
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import time
from scipy.integrate import quad
import warnings
import sys

warnings.filterwarnings('ignore')


# =============================================================================
# ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class CacheManager:
    """ìºì‹œ ê´€ë¦¬ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, cache_dir='tng_api_cache'):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # ìºì‹œ ìƒíƒœ íŒŒì¼
        self.status_file = self.cache_dir / 'cache_status.json'
        self._load_status()
    
    def _load_status(self):
        """ìºì‹œ ìƒíƒœ ë¡œë“œ"""
        if self.status_file.exists():
            with open(self.status_file, 'r') as f:
                self.status = json.load(f)
        else:
            self.status = {
                'subhalo_catalog': False,
                'group_catalog': False,
                'downloaded_galaxies': []
            }
    
    def _save_status(self):
        """ìºì‹œ ìƒíƒœ ì €ì¥"""
        with open(self.status_file, 'w') as f:
            json.dump(self.status, f, indent=2)
    
    def is_cached(self, item_type, item_id=None):
        """ìºì‹œ ì¡´ì¬ í™•ì¸"""
        if item_type == 'subhalo_catalog':
            return self.status.get('subhalo_catalog', False)
        elif item_type == 'group_catalog':
            return self.status.get('group_catalog', False)
        elif item_type == 'galaxy':
            return item_id in self.status.get('downloaded_galaxies', [])
        return False
    
    def mark_cached(self, item_type, item_id=None):
        """ìºì‹œ ì™„ë£Œ í‘œì‹œ"""
        if item_type == 'subhalo_catalog':
            self.status['subhalo_catalog'] = True
        elif item_type == 'group_catalog':
            self.status['group_catalog'] = True
        elif item_type == 'galaxy':
            if item_id not in self.status.get('downloaded_galaxies', []):
                self.status['downloaded_galaxies'].append(item_id)
        
        self._save_status()
    
    def get_cache_info(self):
        """ìºì‹œ ì •ë³´ ë°˜í™˜"""
        total_size = sum(f.stat().st_size for f in self.cache_dir.rglob('*') if f.is_file())
        n_files = len(list(self.cache_dir.rglob('*')))
        
        return {
            'total_size_mb': total_size / (1024 * 1024),
            'n_files': n_files,
            'n_galaxies': len(self.status.get('downloaded_galaxies', [])),
            'has_catalogs': self.status.get('subhalo_catalog', False) and self.status.get('group_catalog', False)
        }
    
    def print_cache_info(self):
        """ìºì‹œ ì •ë³´ ì¶œë ¥"""
        info = self.get_cache_info()
        
        print("\n" + "="*70)
        print("ğŸ’¾ ìºì‹œ ìƒíƒœ")
        print("="*70)
        print(f"  ğŸ“ ìœ„ì¹˜: {self.cache_dir}")
        print(f"  ğŸ“Š í¬ê¸°: {info['total_size_mb']:.1f} MB")
        print(f"  ğŸ“„ íŒŒì¼ ìˆ˜: {info['n_files']}ê°œ")
        print(f"  âœ“ ì¹´íƒˆë¡œê·¸: {'ìˆìŒ' if info['has_catalogs'] else 'ì—†ìŒ'}")
        print(f"  âœ“ ë‹¤ìš´ë¡œë“œëœ ì€í•˜: {info['n_galaxies']}ê°œ")
        
        if info['has_catalogs']:
            print(f"\n  ğŸ’¡ ì¹´íƒˆë¡œê·¸ëŠ” ìºì‹œì—ì„œ ì¦‰ì‹œ ë¡œë“œë©ë‹ˆë‹¤ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)")
        if info['n_galaxies'] > 0:
            print(f"  ğŸ’¡ {info['n_galaxies']}ê°œ ì€í•˜ëŠ” ìºì‹œì—ì„œ ì¦‰ì‹œ ë¡œë“œë©ë‹ˆë‹¤")
        
        print("="*70)


# =============================================================================
# Chabrier IMF í´ë˜ìŠ¤
# =============================================================================

class ChabrierIMF:
    """Chabrier (2003) IMF"""
    
    def __init__(self):
        self.mc = 0.079
        self.sigma = 0.69
        self.A = 0.158
        self.alpha = 2.3
        
    def __call__(self, mass):
        mass = np.atleast_1d(mass)
        imf = np.zeros_like(mass)
        
        mask_low = mass < 1.0
        if np.any(mask_low):
            m_low = mass[mask_low]
            imf[mask_low] = (self.A / m_low) * np.exp(
                -0.5 * (np.log10(m_low) - np.log10(self.mc))**2 / self.sigma**2
            )
        
        mask_high = mass >= 1.0
        if np.any(mask_high):
            m_high = mass[mask_high]
            A_high = self.A * np.exp(
                -0.5 * (np.log10(1.0) - np.log10(self.mc))**2 / self.sigma**2
            )
            imf[mask_high] = A_high * m_high**(-self.alpha)
        
        return imf if len(imf) > 1 else imf[0]
    
    def integrate(self, m_min, m_max):
        result, _ = quad(self, m_min, m_max, limit=100)
        return result


class StellarEvolution:
    """Stellar evolution"""
    
    @staticmethod
    def main_sequence_lifetime(mass):
        return 10.0 * mass**(-2.5)
    
    @staticmethod
    def turnoff_mass(age_gyr):
        return (10.0 / age_gyr)**(1.0 / 2.5)


# =============================================================================
# TNG API Loader (ìºì‹œ ê°•í™” ë²„ì „)
# =============================================================================

class TNGAPILoader:
    """TNG API ë¡œë” - ê°•ë ¥í•œ ìºì‹œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, api_key, simulation='TNG50-1', snapshot=99, cache_dir='tng_cache'):
        self.api_key = api_key
        self.simulation = simulation
        self.snapshot = snapshot
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        self.base_url = "https://www.tng-project.org/api"
        self.headers = {"api-key": self.api_key}
        
        # ìºì‹œ ë§¤ë‹ˆì €
        self.cache_manager = CacheManager(cache_dir)
        
        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = 5
        self.retry_delay = 2
        
        print(f"TNG API Loader ì´ˆê¸°í™”")
        print(f"  ì‹œë®¬ë ˆì´ì…˜: {simulation}")
        print(f"  ìŠ¤ëƒ…ìƒ·: {snapshot}")
        
        self._test_connection()
        
        # ìºì‹œ ì •ë³´ ì¶œë ¥
        self.cache_manager.print_cache_info()
    
    def _test_connection(self):
        """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            url = f"{self.base_url}/{self.simulation}"
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                print(f"âœ“ API ì—°ê²° ì„±ê³µ")
            elif response.status_code == 401:
                print(f"âœ— API Key ì˜¤ë¥˜")
                raise ValueError("Invalid API key")
            else:
                print(f"âœ— API ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                raise ConnectionError(f"API connection failed")
        except requests.exceptions.RequestException as e:
            print(f"âœ— ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            raise
    
    def _make_request_with_retry(self, url, params=None):
        """ì¬ì‹œë„ ë¡œì§"""
        for attempt in range(self.max_retries):
            try:
                response = requests.get(url, headers=self.headers, params=params, timeout=60)
                
                if response.status_code == 200:
                    return response
                elif response.status_code in [502, 503]:
                    if attempt < self.max_retries - 1:
                        wait_time = self.retry_delay * (2 ** attempt)
                        print(f"\n  âš ï¸  ì„œë²„ ì˜¤ë¥˜. {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({attempt+1}/{self.max_retries})")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise RuntimeError(f"ì„œë²„ ì˜¤ë¥˜: {response.status_code}")
                elif response.status_code == 429:
                    wait_time = 60
                    print(f"\n  âš ï¸  Rate limit. {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise RuntimeError(f"API ì˜¤ë¥˜: {response.status_code}")
                    
            except requests.exceptions.Timeout:
                if attempt < self.max_retries - 1:
                    print(f"\n  âš ï¸  Timeout. ì¬ì‹œë„... ({attempt+1}/{self.max_retries})")
                    time.sleep(self.retry_delay)
                    continue
                else:
                    raise
            except requests.exceptions.RequestException as e:
                if attempt < self.max_retries - 1:
                    print(f"\n  âš ï¸  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜. ì¬ì‹œë„...")
                    time.sleep(self.retry_delay)
                    continue
                else:
                    raise
        
        raise RuntimeError("ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")
    
    def get_subhalo_catalog(self):
        """ì„œë¸Œí• ë¡œ ì¹´íƒˆë¡œê·¸ - ìºì‹œ ìš°ì„ """
        print("\nì„œë¸Œí• ë¡œ ì¹´íƒˆë¡œê·¸ ë¡œë”©...")
        
        cache_file = self.cache_dir / f"subhalos_snap{self.snapshot}.json"
        
        # ìºì‹œ í™•ì¸
        if cache_file.exists() and self.cache_manager.is_cached('subhalo_catalog'):
            print(f"  ğŸ’¾ ìºì‹œì—ì„œ ë¡œë“œ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)")
            with open(cache_file, 'r') as f:
                data = json.load(f)
            print(f"  âœ“ {len(data)}ê°œ ì„œë¸Œí• ë¡œ ë¡œë“œ ì™„ë£Œ")
            return data
        
        # API ë‹¤ìš´ë¡œë“œ
        print(f"  ğŸŒ APIì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì²˜ìŒì´ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)")
        
        url = f"{self.base_url}/{self.simulation}/snapshots/{self.snapshot}/subhalos/"
        
        all_subhalos = []
        page = 0
        
        while url:
            page += 1
            if page % 10 == 0:
                print(f"    í˜ì´ì§€ {page}... ({len(all_subhalos)}ê°œ)")
            
            response = self._make_request_with_retry(url)
            data = response.json()
            
            all_subhalos.extend(data['results'])
            url = data['next']
            
            time.sleep(0.2)
        
        # ìºì‹œ ì €ì¥
        with open(cache_file, 'w') as f:
            json.dump(all_subhalos, f)
        
        self.cache_manager.mark_cached('subhalo_catalog')
        
        print(f"  âœ“ {len(all_subhalos)}ê°œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ë° ìºì‹œ ì €ì¥")
        print(f"  ğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ë¶€í„°ëŠ” ì¦‰ì‹œ ë¡œë“œë©ë‹ˆë‹¤!")
        
        return all_subhalos
    
    def get_group_catalog(self):
        """ê·¸ë£¹ ì¹´íƒˆë¡œê·¸ - ìºì‹œ ìš°ì„ """
        print("\nê·¸ë£¹ ì¹´íƒˆë¡œê·¸ ë¡œë”©...")
        
        cache_file = self.cache_dir / f"groups_snap{self.snapshot}.json"
        
        # ìºì‹œ í™•ì¸
        if cache_file.exists() and self.cache_manager.is_cached('group_catalog'):
            print(f"  ğŸ’¾ ìºì‹œì—ì„œ ë¡œë“œ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)")
            with open(cache_file, 'r') as f:
                data = json.load(f)
            print(f"  âœ“ {len(data)}ê°œ ê·¸ë£¹ ë¡œë“œ ì™„ë£Œ")
            return data
        
        # API ë‹¤ìš´ë¡œë“œ
        print(f"  ğŸŒ APIì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        url = f"{self.base_url}/{self.simulation}/snapshots/{self.snapshot}/halos/"
        
        all_groups = []
        page = 0
        
        while url:
            page += 1
            if page % 10 == 0:
                print(f"    í˜ì´ì§€ {page}... ({len(all_groups)}ê°œ)")
            
            response = self._make_request_with_retry(url)
            data = response.json()
            
            all_groups.extend(data['results'])
            url = data['next']
            
            time.sleep(0.2)
        
        # ìºì‹œ ì €ì¥
        with open(cache_file, 'w') as f:
            json.dump(all_groups, f)
        
        self.cache_manager.mark_cached('group_catalog')
        
        print(f"  âœ“ {len(all_groups)}ê°œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ë° ìºì‹œ ì €ì¥")
        
        return all_groups
    
    def get_stellar_particles(self, subhalo_id):
        """ë³„ ì…ì - ìºì‹œ ìš°ì„ """
        cache_file = self.cache_dir / f"stars_subhalo_{subhalo_id}_snap{self.snapshot}.npz"
        
        # ìºì‹œ í™•ì¸
        if cache_file.exists() and self.cache_manager.is_cached('galaxy', subhalo_id):
            print(f"  ğŸ’¾ ìºì‹œì—ì„œ ë¡œë“œ (ë‹¤ìš´ë¡œë“œ ì—†ìŒ)")
            data = np.load(cache_file)
            stellar_data = {key: data[key] for key in data.files}
            n_stars = len(stellar_data.get('Masses', []))
            print(f"  âœ“ {n_stars:,}ê°œ ë³„ ì…ì ë¡œë“œ ì™„ë£Œ")
            return stellar_data
        
        # API ë‹¤ìš´ë¡œë“œ
        print(f"  ğŸŒ ë³„ ì…ì ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        url = f"{self.base_url}/{self.simulation}/snapshots/{self.snapshot}/subhalos/{subhalo_id}/cutout.hdf5"
        
        params = {
            'stars': 'Coordinates,Velocities,Masses,GFM_StellarFormationTime,GFM_InitialMass,GFM_Metallicity'
        }
        
        response = self._make_request_with_retry(url, params=params)
        
        temp_file = self.cache_dir / f"temp_{subhalo_id}.hdf5"
        with open(temp_file, 'wb') as f:
            f.write(response.content)
        
        stellar_data = {}
        with h5py.File(temp_file, 'r') as f:
            if 'PartType4' in f:
                part4 = f['PartType4']
                
                for key in ['Coordinates', 'Velocities', 'Masses', 
                           'GFM_StellarFormationTime', 'GFM_InitialMass', 'GFM_Metallicity']:
                    if key in part4:
                        stellar_data[key] = part4[key][:]
        
        temp_file.unlink()
        
        # ìºì‹œ ì €ì¥
        np.savez_compressed(cache_file, **stellar_data)
        self.cache_manager.mark_cached('galaxy', subhalo_id)
        
        n_stars = len(stellar_data.get('Masses', []))
        print(f"  âœ“ {n_stars:,}ê°œ ë³„ ì…ì ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        
        return stellar_data
    
    def get_subhalo_details(self, subhalo_id):
        """ì„œë¸Œí• ë¡œ ìƒì„¸ ì •ë³´"""
        cache_file = self.cache_dir / f"subhalo_{subhalo_id}_snap{self.snapshot}.json"
        
        if cache_file.exists():
            with open(cache_file, 'r') as f:
                return json.load(f)
        
        url = f"{self.base_url}/{self.simulation}/snapshots/{self.snapshot}/subhalos/{subhalo_id}"
        
        response = self._make_request_with_retry(url)
        data = response.json()
        
        with open(cache_file, 'w') as f:
            json.dump(data, f)
        
        return data


# =============================================================================
# ë‚˜ë¨¸ì§€ í´ë˜ìŠ¤ë“¤ì€ ì´ì „ê³¼ ë™ì¼
# (TNGAPIAdvancedAnalysis ë“±)
# =============================================================================

class TNGAPIAdvancedAnalysis:
    """TNG API + ê³ ê¸‰ ë¶„ì„"""
    
    def __init__(self, api_key, simulation='TNG50-1', snapshot=99, cache_dir='tng_api_cache'):
        self.loader = TNGAPILoader(api_key, simulation, snapshot, cache_dir)
        self.h = 0.6774
        self.imf = ChabrierIMF()
        
        self.subhalo_catalog = None
        self.group_catalog = None
        self.selected_subhalos = []
        self.results = {'galaxies': [], 'summary': {}}
    
    def load_catalogs(self):
        """ì¹´íƒˆë¡œê·¸ ë¡œë“œ"""
        print("\n" + "="*70)
        print("ì¹´íƒˆë¡œê·¸ ë¡œë”©")
        print("="*70)
        
        self.subhalo_catalog = self.loader.get_subhalo_catalog()
        self.group_catalog = self.loader.get_group_catalog()
        
        print("\nâœ“ ì¹´íƒˆë¡œê·¸ ë¡œë”© ì™„ë£Œ")
    
    def select_milkyway_like_galaxies(self):
        """Milky Way-like ì€í•˜ ì„ íƒ"""
        print("\n" + "="*70)
        print("Milky Way-like ì€í•˜ ì„ íƒ")
        print("="*70)
        
        print("\n=== 1. Central Subhalo ì„ íƒ ===")
        central_ids = set()
        for group in self.group_catalog:
            first_sub = group.get('id')
            if first_sub is not None:
                central_ids.add(first_sub)
        
        print(f"Central: {len(central_ids):,}ê°œ")
        
        print("\n=== 2. ë³„ ì§ˆëŸ‰ & SFR í•„í„°ë§ ===")
        candidates = []
        
        for subhalo in self.subhalo_catalog:
            sub_id = subhalo['id']
            
            if sub_id not in central_ids:
                continue
            
            mass_type = subhalo.get('mass_type', [0]*6)
            stellar_mass = mass_type[4] * 1e10 / self.h
            
            if stellar_mass < 4e10 or stellar_mass > 8e10:
                continue
            
            sfr = subhalo.get('sfr', 0)
            if sfr < 1.0 or sfr > 2.0:
                continue
            
            candidates.append({
                'id': sub_id,
                'stellar_mass': stellar_mass,
                'sfr': sfr
            })
        
        print(f"í†µê³¼: {len(candidates)}ê°œ")
        
        self.selected_subhalos = [c['id'] for c in candidates]
        
        if len(candidates) > 0:
            print("\nì„ íƒëœ ì€í•˜ (ì²˜ìŒ 5ê°œ):")
            for i, c in enumerate(candidates[:5]):
                # ìºì‹œ í™•ì¸
                cached = "ğŸ’¾" if self.loader.cache_manager.is_cached('galaxy', c['id']) else "ğŸŒ"
                print(f"  {cached} {i+1}. ID {c['id']}: M* = {c['stellar_mass']:.2e} Msun, SFR = {c['sfr']:.2f} Msun/yr")
            if len(candidates) > 5:
                print(f"  ... ì´ {len(candidates)}ê°œ")
            
            # ìºì‹œëœ ì€í•˜ ìˆ˜
            cached_count = sum(1 for c in candidates if self.loader.cache_manager.is_cached('galaxy', c['id']))
            if cached_count > 0:
                print(f"\n  ğŸ’¡ {cached_count}ê°œ ì€í•˜ëŠ” ì´ë¯¸ ìºì‹œì— ìˆìŠµë‹ˆë‹¤ (ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”)")
        
        print("\n" + "="*70)
        print(f"ìµœì¢… ì„ íƒ: {len(self.selected_subhalos)}ê°œ")
        print("="*70)
        
        return self.selected_subhalos
    
    def analyze_galaxy(self, subhalo_id, mass_bins):
        """ë‹¨ì¼ ì€í•˜ ë¶„ì„"""
        print(f"\n{'='*70}")
        print(f"ì„œë¸Œí• ë¡œ {subhalo_id} ë¶„ì„")
        print(f"{'='*70}")
        
        details = self.loader.get_subhalo_details(subhalo_id)
        stellar_mass = details.get('mass_stars', 0) * 1e10 / self.h
        sfr = details.get('sfr', 0)
        
        print(f"  ë³„ ì§ˆëŸ‰: {stellar_mass:.2e} Msun")
        print(f"  SFR: {sfr:.2f} Msun/yr")
        
        stellar_data = self.loader.get_stellar_particles(subhalo_id)
        
        if 'GFM_InitialMass' not in stellar_data:
            print("  âœ— ë³„ ì…ì ë°ì´í„° ì—†ìŒ")
            return None
        
        initial_masses = stellar_data['GFM_InitialMass'] * 1e10 / self.h
        formation_times = stellar_data['GFM_StellarFormationTime']
        
        valid_mask = formation_times > 0
        initial_masses = initial_masses[valid_mask]
        formation_times = formation_times[valid_mask]
        
        ages_gyr = 13.8 * (1.0 - formation_times)
        
        print(f"  ë³„ ì…ì: {len(initial_masses):,}ê°œ")
        
        counts = self._calculate_stellar_counts(initial_masses, ages_gyr, mass_bins)
        
        return {
            'subhalo_id': int(subhalo_id),
            'stellar_mass': float(stellar_mass),
            'sfr': float(sfr),
            'counts': counts
        }
    
    def _calculate_stellar_counts(self, initial_masses, ages, mass_bins):
        """ë³„ ê°œìˆ˜ ì¬êµ¬ì„±"""
        print("\n  ë³„ ê°œìˆ˜ ì¬êµ¬ì„±...")
        
        n_bins = len(mass_bins) - 1
        N_init_bins = np.zeros(n_bins)
        N_surv_bins = np.zeros(n_bins)
        
        for i in range(n_bins):
            m_low = mass_bins[i]
            m_high = mass_bins[i+1]
            
            mask_bin = (initial_masses >= m_low) & (initial_masses < m_high)
            
            if not np.any(mask_bin):
                continue
            
            total_mass = initial_masses[mask_bin].sum()
            
            N_imf = self.imf.integrate(m_low, m_high)
            
            def mass_weighted_imf(m):
                return m * self.imf(m)
            
            M_weighted, _ = quad(mass_weighted_imf, m_low, m_high, limit=100)
            M_avg_imf = M_weighted / N_imf if N_imf > 0 else (m_low + m_high) / 2
            
            N_init_bins[i] = total_mass / M_avg_imf
            
            ages_bin = ages[mask_bin]
            masses_bin = initial_masses[mask_bin]
            
            N_surviving = 0
            for age, mass in zip(ages_bin, masses_bin):
                if age > 0:
                    m_to = StellarEvolution.turnoff_mass(age)
                    if mass < m_to:
                        N_surviving += mass / M_avg_imf
                else:
                    N_surviving += mass / M_avg_imf
            
            N_surv_bins[i] = N_surviving
        
        N_init_total = N_init_bins.sum()
        N_surv_total = N_surv_bins.sum()
        
        survival_rate_bins = np.divide(N_surv_bins, N_init_bins,
                                       out=np.zeros_like(N_surv_bins),
                                       where=N_init_bins>0)
        
        print(f"    ì´ˆê¸°: {N_init_total:.2e}, ìƒì¡´: {N_surv_total:.2e}, ìƒì¡´ìœ¨: {N_surv_total/N_init_total*100:.1f}%")
        
        return {
            'mass_bins': mass_bins,
            'N_init': N_init_bins,
            'N_surv': N_surv_bins,
            'survival_rate': survival_rate_bins,
            'N_init_total': N_init_total,
            'N_surv_total': N_surv_total
        }
    
    def analyze_all_galaxies(self, mass_bins=None, max_galaxies=None):
        """ëª¨ë“  ì€í•˜ ë¶„ì„"""
        if mass_bins is None:
            mass_bins = np.array([0.08, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0])
        
        galaxies_to_analyze = self.selected_subhalos[:max_galaxies] if max_galaxies else self.selected_subhalos
        
        print(f"\nì´ {len(galaxies_to_analyze)}ê°œ ì€í•˜ ë¶„ì„")
        
        for i, subhalo_id in enumerate(galaxies_to_analyze):
            print(f"\n[{i+1}/{len(galaxies_to_analyze)}]")
            
            try:
                result = self.analyze_galaxy(subhalo_id, mass_bins)
                if result:
                    self.results['galaxies'].append(result)
            except Exception as e:
                print(f"  âœ— ë¶„ì„ ì‹¤íŒ¨: {e}")
                continue
        
        self._compute_summary()
        
        return self.results
    
    def _compute_summary(self):
        """ìš”ì•½ í†µê³„"""
        if len(self.results['galaxies']) == 0:
            return
        
        n = len(self.results['galaxies'])
        
        stellar_masses = [g['stellar_mass'] for g in self.results['galaxies']]
        sfrs = [g['sfr'] for g in self.results['galaxies']]
        N_init_totals = [g['counts']['N_init_total'] for g in self.results['galaxies']]
        N_surv_totals = [g['counts']['N_surv_total'] for g in self.results['galaxies']]
        
        self.results['summary'] = {
            'n_galaxies': n,
            'stellar_mass_mean': float(np.mean(stellar_masses)),
            'stellar_mass_std': float(np.std(stellar_masses)),
            'sfr_mean': float(np.mean(sfrs)),
            'sfr_std': float(np.std(sfrs)),
            'N_init_mean': float(np.mean(N_init_totals)),
            'N_surv_mean': float(np.mean(N_surv_totals)),
            'survival_rate_mean': float(np.mean(N_surv_totals) / np.mean(N_init_totals))
        }
        
        print("\n" + "="*70)
        print("ìš”ì•½ í†µê³„")
        print("="*70)
        print(f"ë¶„ì„ ì€í•˜: {n}ê°œ")
        print(f"í‰ê·  ë³„ ì§ˆëŸ‰: {self.results['summary']['stellar_mass_mean']:.2e} Msun")
        print(f"í‰ê·  SFR: {self.results['summary']['sfr_mean']:.2f} Msun/yr")
        print(f"í‰ê·  ìƒì¡´ìœ¨: {self.results['summary']['survival_rate_mean']*100:.1f}%")
    
    def save_results(self, output_dir='tng_api_results'):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"\nê²°ê³¼ ì €ì¥: {output_dir}")
        
        json_file = output_dir / 'analysis_results.json'
        results_to_save = {
            'summary': self.results['summary'],
            'galaxies': []
        }
        
        for g in self.results['galaxies']:
            results_to_save['galaxies'].append({
                'subhalo_id': g['subhalo_id'],
                'stellar_mass': g['stellar_mass'],
                'sfr': g['sfr'],
                'counts': {
                    'mass_bins': g['counts']['mass_bins'].tolist(),
                    'N_init': g['counts']['N_init'].tolist(),
                    'N_surv': g['counts']['N_surv'].tolist(),
                    'survival_rate': g['counts']['survival_rate'].tolist(),
                    'N_init_total': g['counts']['N_init_total'],
                    'N_surv_total': g['counts']['N_surv_total']
                }
            })
        
        with open(json_file, 'w') as f:
            json.dump(results_to_save, f, indent=2)
        
        print(f"  âœ“ {json_file}")
        
        for g in self.results['galaxies']:
            csv_file = output_dir / f"galaxy_{g['subhalo_id']}_bins.csv"
            
            mass_bins = g['counts']['mass_bins']
            df = pd.DataFrame({
                'mass_bin_low': mass_bins[:-1],
                'mass_bin_high': mass_bins[1:],
                'N_init': g['counts']['N_init'],
                'N_surv': g['counts']['N_surv'],
                'survival_rate': g['counts']['survival_rate']
            })
            
            df.to_csv(csv_file, index=False)
        
        print(f"  âœ“ galaxy_*_bins.csv ({len(self.results['galaxies'])}ê°œ)")
    
    def plot_results(self, output_dir='tng_api_results'):
        """í”Œë¡¯ ìƒì„±"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"\ní”Œë¡¯ ìƒì„±: {output_dir}")
        
        for g in self.results['galaxies']:
            subhalo_id = g['subhalo_id']
            mass_bins = g['counts']['mass_bins']
            survival_rate = g['counts']['survival_rate']
            
            mass_centers = (mass_bins[:-1] + mass_bins[1:]) / 2
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(mass_centers, survival_rate * 100, 'o-', linewidth=2, markersize=8)
            ax.set_xlabel('Stellar Mass (M$_\\odot$)', fontsize=14)
            ax.set_ylabel('Survival Rate (%)', fontsize=14)
            ax.set_title(f'Stellar Survival Rate - Subhalo {subhalo_id}', fontsize=16)
            ax.set_xscale('log')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, 105)
            
            plt.tight_layout()
            plt.savefig(output_dir / f'survival_rate_subhalo_{subhalo_id}.png', dpi=300)
            plt.close()
        
        print(f"  âœ“ survival_rate_subhalo_*.png ({len(self.results['galaxies'])}ê°œ)")


# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*80)
    print("TNG API ë¶„ì„ - ìºì‹œ ìµœì í™” ë²„ì „")
    print("="*80)
    
    API_KEY = "f62123ebe9f9efb18d3ed3567e241450"
    
    simulation = 'TNG50-1'
    snapshot = 99
    cache_dir = 'tng_api_cache'
    output_dir = 'tng_api_results'
    
    mass_bins = np.array([0.08, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0])
    
    try:
        choice = input("\në¶„ì„í•  ì€í•˜ ìˆ˜ [3/5/10/all, ê¸°ë³¸ê°’=3]: ").strip().lower()
        
        if choice == 'all':
            max_galaxies = None
        elif choice == '5':
            max_galaxies = 5
        elif choice == '10':
            max_galaxies = 10
        else:
            max_galaxies = 3
        
        print(f"â†’ {max_galaxies if max_galaxies else 'ëª¨ë“ '} ì€í•˜ ë¶„ì„")
        
    except:
        max_galaxies = 3
    
    try:
        analyzer = TNGAPIAdvancedAnalysis(API_KEY, simulation, snapshot, cache_dir)
        
        print("\n[1/4] ì¹´íƒˆë¡œê·¸ ë‹¤ìš´ë¡œë“œ...")
        analyzer.load_catalogs()
        
        print("\n[2/4] ì€í•˜ ì„ íƒ...")
        selected = analyzer.select_milkyway_like_galaxies()
        
        if len(selected) == 0:
            print("\nâš ï¸  ì„ íƒëœ ì€í•˜ ì—†ìŒ")
            return
        
        print(f"\n[3/4] ë¶„ì„...")
        analyzer.analyze_all_galaxies(mass_bins, max_galaxies=max_galaxies)
        
        if len(analyzer.results['galaxies']) == 0:
            print("\nâš ï¸  ë¶„ì„ ì‹¤íŒ¨")
            return
        
        print(f"\n[4/4] ì €ì¥...")
        analyzer.save_results(output_dir)
        analyzer.plot_results(output_dir)
        
        print("\n" + "="*80)
        print("âœ“ ì™„ë£Œ!")
        print("="*80)
        
        # ìµœì¢… ìºì‹œ ì •ë³´
        analyzer.loader.cache_manager.print_cache_info()
        
        summary = analyzer.results['summary']
        print(f"\nğŸ“Š ê²°ê³¼: {output_dir}/")
        print(f"  â€¢ ë¶„ì„ ì€í•˜: {summary['n_galaxies']}ê°œ")
        print(f"  â€¢ í‰ê·  ìƒì¡´ìœ¨: {summary['survival_rate_mean']*100:.1f}%")
        
        print(f"\nğŸ’¡ ë‹¤ìŒ ì‹¤í–‰ì‹œì—ëŠ” ìºì‹œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤!")
        
    except KeyboardInterrupt:
        print("\n\nì¤‘ë‹¨ë¨")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
